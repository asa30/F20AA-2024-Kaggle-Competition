{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fgs2/f20aa-2024/blob/main/cw2/transformers/BERT_lemmatized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ1hd2SnuFmy",
        "outputId": "ab4ddede-f142-439d-ee43-02b66bd722b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'train.csv' downloaded successfully.\n",
            "File 'test.csv' downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# This is so I don't have to keep uploading on Colab.\n",
        "import requests\n",
        "from requests.auth import HTTPBasicAuth\n",
        "\n",
        "def downloadFileFromRepo(username, repository, branch, filepath, token):\n",
        "    # Construct the URL to download the file from GitHub\n",
        "    url = f\"https://raw.githubusercontent.com/{username}/{repository}/{branch}/{filepath}\"\n",
        "\n",
        "    # Send a GET request to download the file\n",
        "    response = requests.get(url, auth=HTTPBasicAuth(username, token))\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Extract the file name from the URL\n",
        "        fileName = filepath.split('/')[-1]\n",
        "\n",
        "        # Create the 'data' directory if it doesn't exist\n",
        "        if not os.path.exists('data'):\n",
        "            os.makedirs('data')\n",
        "\n",
        "        # Define the file path within the 'data' directory\n",
        "        localFilepath = os.path.join('data', fileName)\n",
        "\n",
        "        # Write the file content to a local file\n",
        "        with open(localFilepath, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"File '{fileName}' downloaded successfully.\")\n",
        "    else:\n",
        "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "\n",
        "username = \"\"\n",
        "repository = \"\"\n",
        "branch = \"\"\n",
        "path_to_file = \"\"\n",
        "repoToken = \"\"\n",
        "downloadFileFromRepo(username, repository, branch, path_to_file, repoToken)\n",
        "\n",
        "# path_to_file = \"cw2/data/trainStemmed.csv\"\n",
        "# downloadFileFromRepo(username, repository, branch, path_to_file, repoToken)\n",
        "\n",
        "path_to_file = \"cw2/data/test.csv\"\n",
        "downloadFileFromRepo(username, repository, branch, path_to_file, repoToken)\n",
        "\n",
        "# path_to_file = \"cw2/data/testStemmed.csv\"\n",
        "# downloadFileFromRepo(username, repository, branch, path_to_file, repoToken)\n",
        "\n",
        "# path_to_file = \"cw2/lemmaTokenizer.json\"\n",
        "# downloadFileFromRepo(username, repository, branch, path_to_file, repoToken)\n",
        "\n",
        "# path_to_file = \"cw2/stemTokenizer.json\"\n",
        "# downloadFileFromRepo(username, repository, branch, path_to_file, repoToken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RujfMzFE1Q1-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxJpdzXbog1y",
        "outputId": "79e00a51-851f-4348-e649-a0a923f02b6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['overall', 'Review'], dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "piD6C_japrsE"
      },
      "outputs": [],
      "source": [
        "texts = df['Review'].tolist()\n",
        "labels = df['overall'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4ffpqDDSpxOu"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self, bert_model_name, num_classes):\n",
        "      super(BERTClassifier, self).__init__()\n",
        "      self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "      outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      pooled_output = outputs.pooler_output\n",
        "      x = self.dropout(pooled_output)\n",
        "      logits = self.fc(x)\n",
        "      return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oLv7g8ihqIsQ"
      },
      "outputs": [],
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "  def __init__(self, texts, labels, tokenizer, max_length):\n",
        "          self.texts = texts\n",
        "          self.labels = labels\n",
        "          self.tokenizer = tokenizer\n",
        "          self.max_length = max_length\n",
        "  def __len__(self):\n",
        "      return len(self.texts)\n",
        "  def __getitem__(self, idx):\n",
        "      text = str(self.texts[idx])\n",
        "      label = self.labels[idx]\n",
        "      encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
        "      return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label-1)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0C86xu9LqLFa"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, optimizer, scheduler, device):\n",
        "  model.train()\n",
        "  for i,batch in enumerate(data_loader):\n",
        "      optimizer.zero_grad()\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['label'].to(device)\n",
        "      outputs = model(input_ids, attention_mask)\n",
        "      loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "      if i % 100 == 0:\n",
        "        print(f\"Batch: {i}\")\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RUjizoW6qNMH"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uSBM5kcuqR6V"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "    return preds.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EZ7ulXfVqUXW"
      },
      "outputs": [],
      "source": [
        "# Set up parameters\n",
        "bert_model_name = 'bert-base-uncased'\n",
        "num_classes = 5\n",
        "max_length = 128\n",
        "batch_size = 128\n",
        "num_epochs = 10\n",
        "learning_rate = 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H68t6wx4qWIv"
      },
      "outputs": [],
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8Dfh86PkqWru"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "18wxltONsRia"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
        "# model.load_state_dict(torch.load('BERTEpoch1.bin'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDnkgbdPsT7h",
        "outputId": "abb8275b-06a0-4ee6-c564-b130ceb7eef5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "l3mtAudLfFX0"
      },
      "outputs": [],
      "source": [
        "# !pip install numba\n",
        "\n",
        "# from numba import cuda\n",
        "# device = cuda.get_current_device()\n",
        "# device.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "DarxHXvfsVU9",
        "outputId": "9c4633d3-c1ac-48fc-9542-1c7771a36ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting notify\n",
            "  Downloading notify-0.3.1.tar.gz (10 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'notify'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'notify'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# !pip install notify\n",
        "# from notify import notify\n",
        "from IPython.display import clear_output\n",
        "\n",
        "df_test = pd.read_csv('data/test.csv')\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "      print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "      train(model, train_dataloader, optimizer, scheduler, device)\n",
        "      accuracy, report = evaluate(model, val_dataloader, device)\n",
        "      print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "      print(report)\n",
        "      torch.save(model.state_dict(), f\"/bert{epoch}e.pt\")\n",
        "      df_submission = pd.DataFrame()\n",
        "      df_submission['id'] = df_test['id']\n",
        "      for index, row in df_test.iterrows():\n",
        "          value = predict_sentiment(row['Review'], model, tokenizer, device)\n",
        "          df_submission.at[index, 'overall'] = value\n",
        "      df_submission['overall'] = predict_sentiment(df_test['Review'], model, tokenizer, device)\n",
        "      print(df_submission)\n",
        "      df_submission.to_csv(f\"submitKaggle{epoch}E.csv\", index = False)\n",
        "      print(\"An epoch has completed! Check your results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "RgPKNDqE9ing",
        "outputId": "fdf5e0ab-1f72-4529-80a2-30b014b089b4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_test' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d4cc8b91a340>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'overall'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
          ]
        }
      ],
      "source": [
        "df_submission = pd.DataFrame()\n",
        "df_submission['id'] = df_test['id']\n",
        "for index, row in df_test.iterrows():\n",
        "    value = predict_sentiment(row['Review'], model, tokenizer, device)\n",
        "    df_submission.at[index, 'overall'] = value\n",
        "#df_submission['overall'] = predict_sentiment(df_test['Review'], model, tokenizer, device)\n",
        "print(df_submission)\n",
        "df_submission.to_csv(f\"submitKaggle{epoch}E.csv\", index = False)\n",
        "with open(f\"submitKaggle{epoch}E.csv\", 'rb') as file:\n",
        "  content = file.read()\n",
        "url = f'https://api.github.com/repos/{username}/{repository}/cw2/results/bertKaggle{epoch}E.csv'\n",
        "headers = {\n",
        "  'Authorization': f'token {repoToken}',\n",
        "  'Content-Type': 'application/json'\n",
        "}\n",
        "payload = {\n",
        "  'message': 'Upload file',\n",
        "  'content': content.decode('utf-8')\n",
        "}\n",
        "response = requests.put(url, headers=headers, json=payload)\n",
        "print(response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXt0bnqcqAjf"
      },
      "outputs": [],
      "source": [
        "df_submission['overall'] = df_submission['overall'] + 1\n",
        "df_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9jCXdobqJNr"
      },
      "outputs": [],
      "source": [
        "df_submission.to_csv(\"submit1Epoch.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydos1HDfplyk"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"BERTEpoch1.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdLquqjTqlwJ"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNsSQ_AZsWwP"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd8-HZqZaj14"
      },
      "outputs": [],
      "source": [
        "model = torch.load(\"/content/drive/MyDrive/data/bert_classifier.pth\")\n",
        "model = BERTClassifier(bert_model_name, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCiHWyzFsYiR"
      },
      "outputs": [],
      "source": [
        "# Test sentiment prediction\n",
        "test_text = \"The movie was great and I really enjoyed the performances of the actors.\"\n",
        "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
        "print(\"The movie was great and I really enjoyed the performances of the actors.\")\n",
        "print(f\"Predicted sentiment: {sentiment}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWhtuJzwKoHD"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S49GC8r7KxKq"
      },
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8kBm-kxK19u"
      },
      "outputs": [],
      "source": [
        "df_submission = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDXMrYLAK4r2"
      },
      "outputs": [],
      "source": [
        "df_submission = pd.DataFrame()\n",
        "df_submission['id'] = df_test['id']\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    # Get the value from df\n",
        "    value = predict_sentiment(row['Review'], model, tokenizer, device)\n",
        "    # Update the corresponding row in df_submission\n",
        "    df_submission.at[index, 'overall'] = value\n",
        "\n",
        "df_submission['overall'] = predict_sentiment(df_test['Review'], model, tokenizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdVwOL-DtQZI"
      },
      "outputs": [],
      "source": [
        "for index, row in df_test.iterrows():\n",
        "    # Get the value from df\n",
        "    value = predict_sentiment(row['Review'], model, tokenizer, device)\n",
        "    # Update the corresponding row in df_submission\n",
        "    df_submission.at[index, 'overall'] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEZB-jKar9hO"
      },
      "outputs": [],
      "source": [
        "df_submission['overall'] = predict_sentiment(df_test['Review'], model, tokenizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpx7hUfzAd6P"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
