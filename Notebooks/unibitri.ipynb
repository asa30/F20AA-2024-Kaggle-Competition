{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dfL = pd.read_csv(\"data/trainLemmatized.csv\")\n",
    "dfS = pd.read_csv(\"data/trainStemmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 50\n",
    "xTrainL, xTestL, yTrainL, yTestL = train_test_split(dfL[\"data\"], dfL['labels'], test_size = 0.2, random_state = seed)\n",
    "xTrainS, xTestS, yTrainS, yTestS = train_test_split(dfS[\"data\"], dfS['labels'], test_size = 0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301827                                     good brush price\n",
       "104581    expected larger size took month receive spacer...\n",
       "16272     superb customer service ever reorder recommend...\n",
       "258216    work great clasp various jewelry project origi...\n",
       "131419    looking nice blank book journaling definitely ...\n",
       "                                ...                        \n",
       "317510                              item exactly advertised\n",
       "321502        nice sturdy dauber worked well pleased result\n",
       "153709                                           work great\n",
       "239499    template cut beautiful tree intricate tree orn...\n",
       "103904    ok looking forward mold really wanted start ma...\n",
       "Name: data, Length: 296368, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainL.reset_index(drop=True, inplace=True)\n",
    "xTestL.reset_index(drop=True, inplace=True)\n",
    "xTrainS.reset_index(drop=True, inplace=True)\n",
    "xTestS.reset_index(drop=True, inplace=True)\n",
    "yTrainL.reset_index(drop=True, inplace=True)\n",
    "yTestL.reset_index(drop=True, inplace=True)\n",
    "yTrainS.reset_index(drop=True, inplace=True)\n",
    "yTestS.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def replaceNAN(txt):\n",
    "    try:\n",
    "        if math.isnan(txt):\n",
    "            return \"\"\n",
    "        else:\n",
    "            return txt\n",
    "    except:\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(xTrainL)):\n",
    "    xTrainL[i] = replaceNAN(xTrainL[i])\n",
    "for i in range(len(xTrainS)):\n",
    "    xTrainS[i] = replaceNAN(xTrainS[i])\n",
    "for i in range(len(xTestL)):\n",
    "    xTestL[i] = replaceNAN(xTestL[i])\n",
    "for i in range(len(xTestS)):\n",
    "    xTestS[i] = replaceNAN(xTestS[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "Lemmatized Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.12      0.00      0.01      2161\n",
      "           2       0.00      0.00      0.00      1916\n",
      "           3       0.15      0.01      0.01      4284\n",
      "           4       0.25      0.01      0.02      9069\n",
      "           5       0.77      0.99      0.87     56662\n",
      "\n",
      "    accuracy                           0.76     74092\n",
      "   macro avg       0.26      0.20      0.18     74092\n",
      "weighted avg       0.63      0.76      0.67     74092\n",
      "\n",
      "\n",
      "Stemmed Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.13      0.01      0.01      2150\n",
      "           2       0.16      0.00      0.00      1931\n",
      "           3       0.21      0.00      0.01      4255\n",
      "           4       0.24      0.01      0.02      9224\n",
      "           5       0.77      0.99      0.86     56532\n",
      "\n",
      "    accuracy                           0.76     74092\n",
      "   macro avg       0.30      0.20      0.18     74092\n",
      "weighted avg       0.63      0.76      0.66     74092\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "unigram = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range = (1, 1), tokenizer = identity,token_pattern=None, preprocessor = identity)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# uni-gram representation with LogisticRegression for lemmatized documents\n",
    "print(\"Unigram\")\n",
    "print(\"Lemmatized Logistic Regression\")\n",
    "unigram.fit(xTrainL, yTrainL)\n",
    "pred = unigram.predict(xTestL)\n",
    "print(classification_report(yTestL, pred))\n",
    "print(\"\")\n",
    "# uni-gram representation with SGDClasLogisticRegressionsifier for stemmed documents\n",
    "print(\"Stemmed Logistic Regression\")\n",
    "unigram.fit(xTrainS, yTrainS)\n",
    "pred = unigram.predict(xTestS)\n",
    "print(classification_report(yTestS, pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram\n",
      "Lemmatized Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.16      0.23      2161\n",
      "           2       0.19      0.03      0.05      1916\n",
      "           3       0.32      0.07      0.12      4284\n",
      "           4       0.35      0.05      0.09      9069\n",
      "           5       0.79      0.98      0.87     56662\n",
      "\n",
      "    accuracy                           0.77     74092\n",
      "   macro avg       0.41      0.26      0.27     74092\n",
      "weighted avg       0.68      0.77      0.69     74092\n",
      "\n",
      "\n",
      "Stemmed Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.14      0.21      2150\n",
      "           2       0.17      0.02      0.03      1931\n",
      "           3       0.32      0.08      0.13      4255\n",
      "           4       0.35      0.05      0.08      9224\n",
      "           5       0.78      0.98      0.87     56532\n",
      "\n",
      "    accuracy                           0.77     74092\n",
      "   macro avg       0.41      0.25      0.26     74092\n",
      "weighted avg       0.68      0.77      0.69     74092\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "bigram = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range = (2, 2), tokenizer = identity,token_pattern=None, preprocessor = identity)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# bi-gram representation with LogisticRegression for lemmatized documents\n",
    "print(\"Bigram\")\n",
    "print(\"Lemmatized Logistic Regression\")\n",
    "bigram.fit(xTrainL, yTrainL)\n",
    "pred = bigram.predict(xTestL)\n",
    "print(classification_report(yTestL, pred))\n",
    "print(\"\")\n",
    "# bi-gram representation with SGDClasLogisticRegressionsifier for stemmed documents\n",
    "print(\"Stemmed Logistic Regression\")\n",
    "bigram.fit(xTrainS, yTrainS)\n",
    "pred = bigram.predict(xTestS)\n",
    "print(classification_report(yTestS, pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram\n",
      "Lemmatized Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.40      0.46      2161\n",
      "           2       0.28      0.09      0.13      1916\n",
      "           3       0.40      0.20      0.27      4284\n",
      "           4       0.46      0.13      0.20      9069\n",
      "           5       0.82      0.98      0.89     56662\n",
      "\n",
      "    accuracy                           0.79     74092\n",
      "   macro avg       0.50      0.36      0.39     74092\n",
      "weighted avg       0.73      0.79      0.74     74092\n",
      "\n",
      "\n",
      "Stemmed Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.38      0.45      2150\n",
      "           2       0.28      0.09      0.14      1931\n",
      "           3       0.40      0.20      0.27      4255\n",
      "           4       0.46      0.12      0.19      9224\n",
      "           5       0.82      0.98      0.89     56532\n",
      "\n",
      "    accuracy                           0.79     74092\n",
      "   macro avg       0.50      0.35      0.39     74092\n",
      "weighted avg       0.73      0.79      0.74     74092\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "trigram = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range = (3, 3), tokenizer = identity,token_pattern=None, preprocessor = identity)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# tri-gram representation with LogisticRegression for lemmatized documents\n",
    "print(\"Trigram\")\n",
    "print(\"Lemmatized Logistic Regression\")\n",
    "trigram.fit(xTrainL, yTrainL)\n",
    "pred = trigram.predict(xTestL)\n",
    "print(classification_report(yTestL, pred))\n",
    "print(\"\")\n",
    "# tri-gram representation with SGDClasLogisticRegressionsifier for stemmed documents\n",
    "print(\"Stemmed Logistic Regression\")\n",
    "trigram.fit(xTrainS, yTrainS)\n",
    "pred = trigram.predict(xTestS)\n",
    "print(classification_report(yTestS, pred))\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
